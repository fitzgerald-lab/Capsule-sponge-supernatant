{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3 Cell-free biomarker performance as a panel in a test cohort \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, roc_curve, confusion_matrix,\n",
    "    recall_score, make_scorer\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# ------------------------------ CONFIG ------------------------------ #\n",
    "DATA_DIR   = \"/Users/suraj/Documents/Supernatant_Cyto_Data\"\n",
    "COMBINED   = f\"{DATA_DIR}/combinedELISA2.csv\"\n",
    "PROSPECT   = f\"{DATA_DIR}/prospectiveELISA2.csv\"\n",
    "\n",
    "TARGET_COL = \"Barretts\"\n",
    "BIOMARKERS = [\"TFF3\", \"REG4\", \"MEP1A\", \"SPINK4\", \"FABP2\", \"CXCL8\"]\n",
    "\n",
    "N_SPLITS    = 5\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# ------------------------------ SCORERS ------------------------------ #\n",
    "def specificity_score(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    return tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "\n",
    "specificity_scorer = make_scorer(specificity_score)\n",
    "sensitivity_scorer = make_scorer(recall_score, pos_label=1)\n",
    "\n",
    "# ------------------------------ DATA ------------------------------ #\n",
    "def load_subset(path):\n",
    "    df = pd.read_csv(path)\n",
    "    return df[[TARGET_COL] + BIOMARKERS].copy()\n",
    "\n",
    "combined    = load_subset(COMBINED)\n",
    "prospective = load_subset(PROSPECT)\n",
    "\n",
    "full_df = pd.concat([combined, prospective], ignore_index=True)\n",
    "X = full_df[BIOMARKERS]\n",
    "y = full_df[TARGET_COL].astype(int)\n",
    "\n",
    "print(\"\\n=== Dataset Info ===\")\n",
    "n = len(full_df); pos = int(full_df[TARGET_COL].sum()); neg = n - pos\n",
    "print(f\"Full Dataset: N={n} | Barretts={pos} | Non-Barretts={neg}\")\n",
    "\n",
    "# ------------------------------ PIPELINE ------------------------------ #\n",
    "def make_pipeline(model):\n",
    "    num_pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    pre = ColumnTransformer([\n",
    "        ('num', num_pipe, BIOMARKERS)\n",
    "    ])\n",
    "    return Pipeline([('pre', pre), ('model', model)])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_SEED)\n",
    "scoring = {\"roc_auc\": \"roc_auc\", \"sensitivity\": sensitivity_scorer, \"specificity\": specificity_scorer}\n",
    "\n",
    "pos_weight = (y == 0).sum() / (y == 1).sum()\n",
    "\n",
    "models = {\n",
    "    \"LogReg\": LogisticRegression(max_iter=10000, class_weight='balanced', solver='liblinear'),\n",
    "    \"Lasso\": LogisticRegressionCV(\n",
    "        Cs=10, cv=5, penalty='l1', solver='saga', scoring='roc_auc',\n",
    "        class_weight='balanced', max_iter=10000, random_state=RANDOM_SEED\n",
    "    ),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=500, class_weight='balanced', random_state=RANDOM_SEED),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        n_estimators=300, learning_rate=0.05, max_depth=4,\n",
    "        subsample=0.9, colsample_bytree=0.9, scale_pos_weight=pos_weight,\n",
    "        eval_metric='logloss', use_label_encoder=False, random_state=RANDOM_SEED\n",
    "    ),\n",
    "    \"LightGBM\": LGBMClassifier(\n",
    "        n_estimators=300, learning_rate=0.05, subsample=0.9,\n",
    "        colsample_bytree=0.9, class_weight='balanced',\n",
    "        random_state=RANDOM_SEED, verbosity=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "# ------------------------------ TRAIN + EVAL ------------------------------ #\n",
    "all_results = []\n",
    "cv_roc_curves = {model: [] for model in models}\n",
    "for name, base_model in models.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    pipe = make_pipeline(base_model)\n",
    "    fold_probs = []\n",
    "    fold_true = []\n",
    "    scores = cross_validate(pipe, X, y, cv=cv, scoring=scoring, n_jobs=-1, return_estimator=True)\n",
    "\n",
    "    for train_idx, test_idx in cv.split(X, y):\n",
    "        pipe.fit(X.iloc[train_idx], y.iloc[train_idx])\n",
    "        probs = pipe.predict_proba(X.iloc[test_idx])[:, 1]\n",
    "        fold_probs.extend(probs)\n",
    "        fold_true.extend(y.iloc[test_idx])\n",
    "\n",
    "    pipe.fit(X, y)\n",
    "    all_results.append({\n",
    "        \"name\": name, \"pipeline\": pipe,\n",
    "        \"cv_auc_mean\": scores['test_roc_auc'].mean(),\n",
    "        \"cv_auc_sd\": scores['test_roc_auc'].std(),\n",
    "        \"cv_sens_mean\": scores['test_sensitivity'].mean(),\n",
    "        \"cv_sens_sd\": scores['test_sensitivity'].std(),\n",
    "        \"cv_spec_mean\": scores['test_specificity'].mean(),\n",
    "        \"cv_spec_sd\": scores['test_specificity'].std(),\n",
    "        \"cv_probs\": np.array(fold_probs),\n",
    "        \"cv_true\": np.array(fold_true)\n",
    "    })\n",
    "\n",
    "# ------------------------------ ROC CURVES (CV) ------------------------------ #\n",
    "def roc_cv_panel(results):\n",
    "    plt.figure(figsize=(6,5))\n",
    "    desired_order = [\"LightGBM\", \"XGBoost\", \"RandomForest\", \"LogReg\", \"Lasso\"]\n",
    "    results_sorted = sorted(results, key=lambda x: desired_order.index(x[\"name\"]) if x[\"name\"] in desired_order else 99)\n",
    "    for r in results_sorted:\n",
    "        fpr, tpr, _ = roc_curve(r[\"cv_true\"], r[\"cv_probs\"])\n",
    "        auc = roc_auc_score(r[\"cv_true\"], r[\"cv_probs\"])\n",
    "        plt.plot(fpr, tpr, label=f\"{r['name']} (CV AUC={auc:.2f})\")\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.title(\"Cross-Validated ROC Curves\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "roc_cv_panel(all_results)\n",
    "\n",
    "# ------------------------------ SHAP ANALYSIS FOR LIGHTGBM ------------------------------ #\n",
    "lgb_res = next((r for r in all_results if r['name'] == 'LightGBM'), None)\n",
    "if lgb_res is not None:\n",
    "    model = lgb_res['pipeline'].named_steps['model']\n",
    "    X_proc = lgb_res['pipeline'].named_steps['pre'].transform(X)\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_proc)\n",
    "    if isinstance(shap_values, list) and len(shap_values) > 1:\n",
    "        shap_values = shap_values[1]\n",
    "\n",
    "    shap.summary_plot(shap_values, X_proc, feature_names=BIOMARKERS, plot_type='bar')\n",
    "    shap.summary_plot(shap_values, X_proc, feature_names=BIOMARKERS)\n",
    "    shap.dependence_plot(\"CXCL8\", shap_values, X_proc, feature_names=BIOMARKERS)\n",
    "\n",
    "# ------------------------------ PERFORMANCE TABLE ------------------------------ #\n",
    "perf_rows = []\n",
    "for r in all_results:\n",
    "    perf_rows.append({\n",
    "        \"Model\": r[\"name\"],\n",
    "        \"CV AUC (mean±sd)\": f\"{r['cv_auc_mean']:.3f} ± {r['cv_auc_sd']:.3f}\",\n",
    "        \"CV Sens (mean±sd)\": f\"{r['cv_sens_mean']:.2f} ± {r['cv_sens_sd']:.2f}\",\n",
    "        \"CV Spec (mean±sd)\": f\"{r['cv_spec_mean']:.2f} ± {r['cv_spec_sd']:.2f}\"\n",
    "    })\n",
    "perf_df = pd.DataFrame(perf_rows).sort_values(\"CV AUC (mean±sd)\", ascending=False)\n",
    "print(\"\\nPerformance Table:\")\n",
    "print(perf_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 4 Secretory protein panel performance in an external prospective test cohort. \n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import textwrap\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, roc_curve, confusion_matrix,\n",
    "    recall_score, make_scorer\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# ------------------------------ CONFIG ------------------------------ #\n",
    "DATA_DIR   = \"/Users/suraj/Documents/Supernatant_Cyto_Data\"\n",
    "COMBINED   = f\"{DATA_DIR}/combinedELISA2.csv\"\n",
    "PROSPECT   = f\"{DATA_DIR}/prospectiveELISA2.csv\"\n",
    "EXTERNAL   = f\"{DATA_DIR}/prospective_Final_2.csv\"\n",
    "\n",
    "TARGET_COL = \"Barretts\"\n",
    "BIOMARKERS = [\"TFF3\", \"REG4\", \"MEP1A\", \"SPINK4\", \"FABP2\", \"CXCL8\"]\n",
    "\n",
    "N_SPLITS    = 5\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# ------------------------------ SCORERS ------------------------------ #\n",
    "def specificity_score(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    return tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "\n",
    "specificity_scorer = make_scorer(specificity_score)\n",
    "sensitivity_scorer = make_scorer(recall_score, pos_label=1)\n",
    "\n",
    "# ------------------------------ DATA ------------------------------ #\n",
    "def load_subset(path):\n",
    "    df = pd.read_csv(path)\n",
    "    return df[[TARGET_COL] + BIOMARKERS].copy()\n",
    "\n",
    "combined    = load_subset(COMBINED)\n",
    "prospective = load_subset(PROSPECT)\n",
    "external    = load_subset(EXTERNAL)\n",
    "\n",
    "dev_df = pd.concat([combined, prospective], ignore_index=True)\n",
    "X_dev = dev_df[BIOMARKERS]\n",
    "y_dev = dev_df[TARGET_COL].astype(int)\n",
    "X_ext = external[BIOMARKERS]\n",
    "y_ext = external[TARGET_COL].astype(int)\n",
    "\n",
    "print(\"\\n=== Cohort counts ===\")\n",
    "for name, df in [(\"Development (CV)\", dev_df), (\"External (hold-out)\", external)]:\n",
    "    n = len(df); pos = int(df[TARGET_COL].sum()); neg = n - pos\n",
    "    print(f\"{name:22s}  N={n:4d} | Barretts={pos:3d} | Non-Barretts={neg:3d}\")\n",
    "\n",
    "# ------------------------------ PIPELINE ------------------------------ #\n",
    "def make_pipeline(model):\n",
    "    num_pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    pre = ColumnTransformer([\n",
    "        ('num', num_pipe, BIOMARKERS)\n",
    "    ])\n",
    "    return Pipeline([('pre', pre), ('model', model)])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_SEED)\n",
    "scoring = {\"roc_auc\": \"roc_auc\", \"sensitivity\": sensitivity_scorer, \"specificity\": specificity_scorer}\n",
    "\n",
    "pos_weight = (y_dev == 0).sum() / (y_dev == 1).sum()\n",
    "\n",
    "models = {\n",
    "    \"LogReg\": LogisticRegression(max_iter=10000, class_weight='balanced', solver='liblinear'),\n",
    "    \"Lasso\": LogisticRegressionCV(\n",
    "        Cs=10, cv=5, penalty='l1', solver='saga', scoring='roc_auc',\n",
    "        class_weight='balanced', max_iter=10000, random_state=RANDOM_SEED\n",
    "    ),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=500, class_weight='balanced', random_state=RANDOM_SEED),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        n_estimators=300, learning_rate=0.05, max_depth=4,\n",
    "        subsample=0.9, colsample_bytree=0.9, scale_pos_weight=pos_weight,\n",
    "        eval_metric='logloss', use_label_encoder=False, random_state=RANDOM_SEED\n",
    "    ),\n",
    "    \"LightGBM\": LGBMClassifier(\n",
    "        n_estimators=300, learning_rate=0.05, subsample=0.9,\n",
    "        colsample_bytree=0.9, class_weight='balanced',\n",
    "        random_state=RANDOM_SEED, verbosity=-1  # suppress warning\n",
    "    )\n",
    "}\n",
    "\n",
    "# ------------------------------ TRAIN + EVAL ------------------------------ #\n",
    "def evaluate_on_external(pipe, X_ext, y_ext):\n",
    "    probs = pipe.predict_proba(X_ext)[:, 1]\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "    auc = roc_auc_score(y_ext, probs)\n",
    "    sens = recall_score(y_ext, preds)\n",
    "    spec = specificity_score(y_ext, preds)\n",
    "    cm = confusion_matrix(y_ext, preds)\n",
    "    return dict(auc=auc, sens=sens, spec=spec, probs=probs, preds=preds, cm=cm)\n",
    "\n",
    "all_results = []\n",
    "for name, base_model in models.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    pipe = make_pipeline(base_model)\n",
    "    scores = cross_validate(pipe, X_dev, y_dev, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "\n",
    "    pipe.fit(X_dev, y_dev)\n",
    "    ext_metrics = evaluate_on_external(pipe, X_ext, y_ext)\n",
    "\n",
    "    all_results.append({\n",
    "        \"name\": name, \"pipeline\": pipe,\n",
    "        \"cv_auc_mean\": scores['test_roc_auc'].mean(),\n",
    "        \"cv_auc_sd\": scores['test_roc_auc'].std(),\n",
    "        \"cv_sens_mean\": scores['test_sensitivity'].mean(),\n",
    "        \"cv_sens_sd\": scores['test_sensitivity'].std(),\n",
    "        \"cv_spec_mean\": scores['test_specificity'].mean(),\n",
    "        \"cv_spec_sd\": scores['test_specificity'].std(),\n",
    "        \"external\": ext_metrics\n",
    "    })\n",
    "\n",
    "# ------------------------------ ROC PLOT ------------------------------ #\n",
    "plt.figure(figsize=(6,5))\n",
    "for r in all_results:\n",
    "    fpr, tpr, _ = roc_curve(y_ext, r['external']['probs'])\n",
    "    plt.plot(fpr, tpr, label=f\"{r['name']} (AUC={r['external']['auc']:.2f})\")\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.title(\"External Validation ROC Curves\")\n",
    "plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# ------------------------------ SHAP ANALYSIS FOR LIGHTGBM ------------------------------ #\n",
    "lgb_res = next((r for r in all_results if r['name'] == 'LightGBM'), None)\n",
    "if lgb_res is not None:\n",
    "    model = lgb_res['pipeline'].named_steps['model']\n",
    "    X_proc = lgb_res['pipeline'].named_steps['pre'].transform(X_dev)\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_proc)\n",
    "    if isinstance(shap_values, list) and len(shap_values) > 1:\n",
    "        shap_values = shap_values[1]\n",
    "\n",
    "    shap.summary_plot(shap_values, X_proc, feature_names=BIOMARKERS, plot_type='bar')\n",
    "    shap.summary_plot(shap_values, X_proc, feature_names=BIOMARKERS)\n",
    "\n",
    "    # Optional: investigate CXCL8\n",
    "    shap.dependence_plot(\"CXCL8\", shap_values, X_proc, feature_names=BIOMARKERS)\n",
    "\n",
    "# ------------------------------ CONFUSION MATRIX ------------------------------ #\n",
    "    cm = lgb_res['external']['cm']\n",
    "    plt.figure(figsize=(4,3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Barretts','Barretts'], yticklabels=['Non-Barretts','Barretts'])\n",
    "    plt.title('External Confusion Matrix - LightGBM')\n",
    "    plt.xlabel('Predicted'); plt.ylabel('True')\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# ------------------------------ PERFORMANCE TABLE ------------------------------ #\n",
    "perf_rows = []\n",
    "for r in all_results:\n",
    "    perf_rows.append({\n",
    "        \"Model\": r[\"name\"],\n",
    "        \"CV AUC (mean±sd)\": f\"{r['cv_auc_mean']:.3f} ± {r['cv_auc_sd']:.3f}\",\n",
    "        \"CV Sens (mean±sd)\": f\"{r['cv_sens_mean']:.2f} ± {r['cv_sens_sd']:.2f}\",\n",
    "        \"CV Spec (mean±sd)\": f\"{r['cv_spec_mean']:.2f} ± {r['cv_spec_sd']:.2f}\",\n",
    "        \"External AUC\": f\"{r['external']['auc']:.3f}\",\n",
    "        \"External Sens/Spec\": f\"Sens {r['external']['sens']:.2f} | Spec {r['external']['spec']:.2f}\"\n",
    "    })\n",
    "perf_df = pd.DataFrame(perf_rows).sort_values(\"External AUC\", ascending=False)\n",
    "print(\"\\nPerformance Table:\")\n",
    "print(perf_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 5 Reduced secretory protein panel performance on a more sensitive assay platform. \n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, roc_curve, recall_score,\n",
    "    confusion_matrix, ConfusionMatrixDisplay, make_scorer\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "# ------------------------------ CONFIG ------------------------------ #\n",
    "DATA_PATH  = \"/Users/suraj/Documents/Supernatant_Cyto_Data/Dec 2025/All ELISA cohorts.csv\"\n",
    "TARGET_COL = \"Barretts\"\n",
    "\n",
    "ALL_MARKERS = [\n",
    "    \"TFF3\",\n",
    "    \"MEP1A\",\n",
    "    \"SPINK4\",\n",
    "    \"CXCL8\",\n",
    "    \"Simoa REG4\",\n",
    "    \"Simoa FABP2\",\n",
    "    \"Simoa TFF3\"\n",
    "]\n",
    "\n",
    "N_SPLITS    = 5\n",
    "RANDOM_SEED = 42\n",
    "BOOTSTRAPS  = 2000\n",
    "\n",
    "\n",
    "# ------------------------------ DATA ------------------------------ #\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df[TARGET_COL] = df[TARGET_COL].astype(int)\n",
    "df = df[[TARGET_COL] + ALL_MARKERS].dropna().copy()\n",
    "\n",
    "X_full = df[ALL_MARKERS]\n",
    "y_full = df[TARGET_COL].values\n",
    "\n",
    "print(f\"\\nLoaded dataset: N={len(df)}, BE={y_full.sum()}, Controls={len(df)-y_full.sum()}\")\n",
    "\n",
    "\n",
    "# ------------------------------ PIPELINE ------------------------------ #\n",
    "def make_pipeline(model, feats):\n",
    "    num_pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "    pre = ColumnTransformer(\n",
    "        [(\"num\", num_pipe, feats)],\n",
    "        sparse_threshold=0.0\n",
    "    )\n",
    "    return Pipeline([(\"pre\", pre), (\"model\", model)])\n",
    "\n",
    "\n",
    "# ------------------------------ METRICS ------------------------------ #\n",
    "def specificity_score(y_true, y_pred):\n",
    "    tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    return tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "\n",
    "specificity_scorer = make_scorer(specificity_score)\n",
    "sensitivity_scorer = make_scorer(recall_score, pos_label=1)\n",
    "\n",
    "\n",
    "# ------------------------------ BOOTSTRAP CI ------------------------------ #\n",
    "def bootstrap_ci(y_true, y_hat, metric_fn, n_boot=BOOTSTRAPS, alpha=0.95):\n",
    "    rng = np.random.RandomState(42)\n",
    "    stats = []\n",
    "\n",
    "    for _ in range(n_boot):\n",
    "        idx = resample(np.arange(len(y_true)), random_state=rng)\n",
    "        try:\n",
    "            stats.append(metric_fn(y_true[idx], y_hat[idx]))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    lower = np.percentile(stats, (1 - alpha) / 2 * 100)\n",
    "    upper = np.percentile(stats, (1 + alpha) / 2 * 100)\n",
    "    return lower, upper\n",
    "\n",
    "\n",
    "# ------------------------------ FEATURE RANKING ------------------------------ #\n",
    "rf_base = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rank_pipe = make_pipeline(rf_base, ALL_MARKERS)\n",
    "rank_pipe.fit(X_full, y_full)\n",
    "\n",
    "importances = pd.Series(\n",
    "    rank_pipe.named_steps[\"model\"].feature_importances_,\n",
    "    index=ALL_MARKERS\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "feature_order = list(importances.index)\n",
    "\n",
    "print(\"\\nFeature importances:\")\n",
    "print(importances)\n",
    "\n",
    "\n",
    "# ------------------------------ DROP-TEST ------------------------------ #\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_SEED)\n",
    "results = []\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "\n",
    "for k in range(len(feature_order), 1, -1):\n",
    "    feats = feature_order[:k]\n",
    "    pipe = make_pipeline(rf_base, feats)\n",
    "\n",
    "    oof_probs = cross_val_predict(\n",
    "        pipe, X_full[feats], y_full,\n",
    "        cv=cv, method=\"predict_proba\", n_jobs=-1\n",
    "    )[:, 1]\n",
    "\n",
    "    oof_pred = (oof_probs >= 0.5).astype(int)\n",
    "\n",
    "    auc = roc_auc_score(y_full, oof_probs)\n",
    "    sens = recall_score(y_full, oof_pred)\n",
    "    spec = specificity_score(y_full, oof_pred)\n",
    "\n",
    "    auc_ci = bootstrap_ci(y_full, oof_probs, roc_auc_score)\n",
    "    sens_ci = bootstrap_ci(y_full, oof_pred, lambda yt, yp: recall_score(yt, yp))\n",
    "    spec_ci = bootstrap_ci(y_full, oof_pred, specificity_score)\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_full, oof_probs)\n",
    "    plt.plot(fpr, tpr, label=f\"Top-{k} ({', '.join(feats)}) (AUC={auc:.2f})\")\n",
    "\n",
    "    results.append({\n",
    "        \"k\": k,\n",
    "        \"Features\": \", \".join(feats),\n",
    "        \"OOF AUC (95% CI)\": f\"{auc:.3f} [{auc_ci[0]:.3f}–{auc_ci[1]:.3f}]\",\n",
    "        \"Sens @0.5 (95% CI)\": f\"{sens:.2f} [{sens_ci[0]:.2f}–{sens_ci[1]:.2f}]\",\n",
    "        \"Spec @0.5 (95% CI)\": f\"{spec:.2f} [{spec_ci[0]:.2f}–{spec_ci[1]:.2f}]\"\n",
    "    })\n",
    "\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.title(\"ROC Curves — Drop Test (Random Forest)\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ------------------------------ CONFUSION MATRIX (TOP-2) ------------------------------ #\n",
    "top2_feats = feature_order[:2]\n",
    "print(f\"\\nPlotting confusion matrix for Top-2 markers: {top2_feats}\")\n",
    "\n",
    "pipe_top2 = make_pipeline(rf_base, top2_feats)\n",
    "\n",
    "oof_probs_top2 = cross_val_predict(\n",
    "    pipe_top2, X_full[top2_feats], y_full,\n",
    "    cv=cv, method=\"predict_proba\", n_jobs=-1\n",
    ")[:, 1]\n",
    "\n",
    "oof_pred_top2 = (oof_probs_top2 >= 0.5).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_full, oof_pred_top2)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=[\"Control\", \"BE\"])\n",
    "\n",
    "disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
    "plt.title(f\"Confusion Matrix — Top-2 ({', '.join(top2_feats)})\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ------------------------------ SUMMARY TABLE ------------------------------ #\n",
    "summary_df = pd.DataFrame(results)\n",
    "print(\"\\n=== Summary (OOF metrics with 95% CI) ===\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
